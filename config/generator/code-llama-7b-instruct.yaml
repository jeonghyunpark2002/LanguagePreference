init_args: 
  _target_: models.generators.llm.LLM
  model_name: "meta-llama/CodeLlama-7b-Instruct-hf"
  max_new_tokens: 512
  max_length: 2048
  quantization: "int4"
  batch_size: 8
